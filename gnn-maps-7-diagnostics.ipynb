{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f09d02",
   "metadata": {},
   "source": [
    "# GNN-MAPS: Diagnostic Experiments\n",
    "\n",
    "## üî¨ Goal: Figure Out WHY GNN is Underperforming\n",
    "\n",
    "**The Problem**:\n",
    "- MLP: 88.2% F1\n",
    "- GNN: 83.2% F1 (5 pp WORSE!)\n",
    "- GNN should BEAT MLP when spatial patterns exist\n",
    "\n",
    "**The Hypothesis**: K=5 neighbors is TOO SMALL\n",
    "- With 100K+ cells, K=5 = only immediate neighbors\n",
    "- 2-layer GNN with K=5 ‚Üí receptive field of only ~25 cells (0.025% of tissue)\n",
    "- Biological spatial patterns likely span 10-20+ cells\n",
    "\n",
    "## üß™ Three Diagnostic Experiments:\n",
    "\n",
    "### **Experiment 1: K-Sensitivity Analysis** ‚≠ê MOST IMPORTANT\n",
    "- Test K = 5, 10, 15, 20, 25\n",
    "- Plot K vs F1-score\n",
    "- **Expected**: If K is the issue ‚Üí performance improves with larger K\n",
    "- **If flat**: K is NOT the issue ‚Üí problem is elsewhere\n",
    "\n",
    "### **Experiment 2: Spatial Pattern Visualization**\n",
    "- Plot each cell type in X-Y space\n",
    "- Visual inspection: Are cell types clustered or randomly distributed?\n",
    "- **Expected**: If clustered ‚Üí spatial patterns exist ‚Üí GNN SHOULD work\n",
    "- **If random**: No patterns ‚Üí GNN will never beat MLP\n",
    "\n",
    "### **Experiment 3: Random Graph Baseline**\n",
    "- Train GNN with: (1) True KNN graph, (2) Random graph, (3) No edges\n",
    "- **Expected**: True > Random > No edges\n",
    "- **If True ‚âà Random**: GNN is NOT using the graph structure!\n",
    "\n",
    "---\n",
    "\n",
    "**Runtime**: ~1-2 hours on Kaggle P100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb22f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric and its dependencies (Kaggle-compatible)\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "!pip install -q torch-geometric\n",
    "\n",
    "import torch\n",
    "pytorch_version = torch.__version__.split('+')[0]\n",
    "cuda_version = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"\\nInstalling PyG extensions for PyTorch {pytorch_version} and CUDA {cuda_version}...\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{pytorch_version}+cu{cuda_version}.html\n",
    "else:\n",
    "    !pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{pytorch_version}+cpu.html\n",
    "\n",
    "print(\"\\n‚úÖ PyTorch Geometric installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556dbb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"‚úÖ All libraries loaded!\")\n",
    "print(f\"   PyTorch: {torch.__version__}\")\n",
    "print(f\"   Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad5662",
   "metadata": {},
   "source": [
    "# 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb2409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"/kaggle/input/chl-codex-annotated/cHL_CODEX_annotation.csv\")\n",
    "print(f\"Dataset: {df.shape[0]:,} cells √ó {df.shape[1]} features\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "x_col = 'X_cent'\n",
    "y_col = 'Y_cent'\n",
    "label_col = 'cellType'\n",
    "\n",
    "marker_cols = [\n",
    "    'BCL.2', 'CCR6', 'CD11b', 'CD11c', 'CD15', 'CD16', 'CD162', 'CD163',\n",
    "    'CD2', 'CD20', 'CD206', 'CD25', 'CD30', 'CD31', 'CD4', 'CD44',\n",
    "    'CD45RA', 'CD45RO', 'CD45', 'CD5', 'CD56', 'CD57', 'CD68', 'CD69',\n",
    "    'CD7', 'CD8', 'Collagen.4', 'Cytokeratin', 'DAPI.01', 'EGFR',\n",
    "    'FoxP3', 'Granzyme.B', 'HLA.DR', 'IDO.1', 'LAG.3', 'MCT', 'MMP.9',\n",
    "    'MUC.1', 'PD.1', 'PD.L1', 'Podoplanin', 'T.bet', 'TCR.g.d', 'TCRb',\n",
    "    'Tim.3', 'VISA', 'Vimentin', 'a.SMA', 'b.Catenin'\n",
    "]\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(df[marker_cols].values)\n",
    "x = torch.tensor(X_normalized, dtype=torch.float)\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = sorted(df[label_col].unique())\n",
    "label_map = {name: i for i, name in enumerate(unique_labels)}\n",
    "y = torch.tensor(df[label_col].map(label_map).values, dtype=torch.long)\n",
    "num_classes = len(label_map)\n",
    "\n",
    "# Get coordinates\n",
    "coords = df[[x_col, y_col]].values\n",
    "\n",
    "# Random train/test split (80/20)\n",
    "torch.manual_seed(42)\n",
    "random_perm = torch.randperm(len(df))\n",
    "n_train = int(0.8 * len(df))\n",
    "train_mask = torch.zeros(len(df), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(df), dtype=torch.bool)\n",
    "train_mask[random_perm[:n_train]] = True\n",
    "test_mask[random_perm[n_train:]] = True\n",
    "\n",
    "print(f\"\\n‚úÖ Prepared:\")\n",
    "print(f\"   Features: {len(marker_cols)} markers\")\n",
    "print(f\"   Labels: {num_classes} cell types\")\n",
    "print(f\"   Train: {train_mask.sum():,} | Test: {test_mask.sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b75e7c",
   "metadata": {},
   "source": [
    "# 2. Experiment 2: Spatial Pattern Visualization (Do First!)\n",
    "\n",
    "Before testing different K values, let's check if spatial patterns even exist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc72c195",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT 2: SPATIAL PATTERN VISUALIZATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get top cell types by count\n",
    "cell_type_counts = df[label_col].value_counts()\n",
    "top_cell_types = cell_type_counts.head(9).index.tolist()\n",
    "\n",
    "print(f\"\\nVisualizing top 9 cell types (out of {num_classes}):\")\n",
    "for i, ct in enumerate(top_cell_types, 1):\n",
    "    count = cell_type_counts[ct]\n",
    "    pct = 100 * count / len(df)\n",
    "    print(f\"  {i}. {ct:<30s} {count:>6,} cells ({pct:>5.2f}%)\")\n",
    "\n",
    "# Create 3x3 grid of spatial plots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(18, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, cell_type in enumerate(top_cell_types):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Get cells of this type\n",
    "    mask = (df[label_col] == cell_type).values\n",
    "    type_coords = coords[mask]\n",
    "    other_coords = coords[~mask]\n",
    "    \n",
    "    # Plot: other cells (gray, background) + this type (colored)\n",
    "    ax.scatter(other_coords[:, 0], other_coords[:, 1], \n",
    "               c='lightgray', s=0.5, alpha=0.2, label='Other')\n",
    "    ax.scatter(type_coords[:, 0], type_coords[:, 1], \n",
    "               c=f'C{idx}', s=2, alpha=0.7, label=cell_type)\n",
    "    \n",
    "    ax.set_title(f\"{cell_type}\\n({cell_type_counts[cell_type]:,} cells)\", \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('X Position', fontsize=9)\n",
    "    ax.set_ylabel('Y Position', fontsize=9)\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Spatial Distribution of Top 9 Cell Types\\n(Are they clustered or random?)', \n",
    "             fontsize=16, fontweight='bold', y=1.01)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VISUAL INSPECTION GUIDE:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ CLUSTERED (good for GNN):\")\n",
    "print(\"   - Cells form distinct regions/patches\")\n",
    "print(\"   - Clear spatial organization\")\n",
    "print(\"   ‚Üí GNN should be able to learn these patterns!\")\n",
    "print(\"\\n‚ùå RANDOM (bad for GNN):\")\n",
    "print(\"   - Cells uniformly scattered across tissue\")\n",
    "print(\"   - No clear spatial structure\")\n",
    "print(\"   ‚Üí No spatial pattern to learn ‚Üí GNN will never beat MLP\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fce70a",
   "metadata": {},
   "source": [
    "# 3. Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615277b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    \"\"\"2-layer GraphSAGE (same as previous experiments)\"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "print(\"‚úÖ GraphSAGE model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57429457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training functions\n",
    "def train_epoch(model, data, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, mask):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    y_true = data.y[mask].cpu().numpy()\n",
    "    y_pred = pred[mask].cpu().numpy()\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return f1\n",
    "\n",
    "def quick_train(model, data, lr=0.001, epochs=100, patience=20, verbose=False):\n",
    "    \"\"\"\n",
    "    Fast training for diagnostic purposes.\n",
    "    Reduced epochs (100 instead of 500) to speed up experiments.\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    best_f1 = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss = train_epoch(model, data, optimizer)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            test_f1 = evaluate(model, data, data.test_mask)\n",
    "            \n",
    "            if test_f1 > best_f1:\n",
    "                best_f1 = test_f1\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if verbose and epoch % 20 == 0:\n",
    "                print(f\"Epoch {epoch:3d} | Loss: {loss:.4f} | Test F1: {test_f1:.4f}\")\n",
    "            \n",
    "            if patience_counter >= patience // 10:\n",
    "                if verbose:\n",
    "                    print(f\"Early stop at epoch {epoch}\")\n",
    "                break\n",
    "    \n",
    "    return best_f1\n",
    "\n",
    "print(\"‚úÖ Training functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfbc0b5",
   "metadata": {},
   "source": [
    "# 4. Experiment 1: K-Sensitivity Analysis ‚≠ê\n",
    "\n",
    "**THE BIG TEST**: Does performance improve with larger K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d01ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT 1: K-SENSITIVITY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test different K values\n",
    "k_values = [5, 10, 15, 20, 25]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nüíª Device: {device}\")\n",
    "\n",
    "results_k_sensitivity = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Testing K = {k} neighbors\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Build KNN graph with K neighbors\n",
    "    print(f\"Building KNN graph with K={k}...\")\n",
    "    nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='ball_tree').fit(coords)\n",
    "    distances, indices = nbrs.kneighbors(coords)\n",
    "    \n",
    "    source_nodes = np.repeat(np.arange(len(df)), k)\n",
    "    target_nodes = indices[:, 1:].flatten()  # Skip self\n",
    "    edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "    \n",
    "    print(f\"‚úÖ Graph built: {edge_index.shape[1]:,} edges\")\n",
    "    \n",
    "    # Create data object\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        y=y,\n",
    "        train_mask=train_mask,\n",
    "        test_mask=test_mask\n",
    "    ).to(device)\n",
    "    \n",
    "    # Train model (quick training for diagnostics)\n",
    "    print(f\"Training GNN (100 epochs with early stopping)...\")\n",
    "    model = GraphSAGE(len(marker_cols), 512, num_classes, dropout=0.1).to(device)\n",
    "    best_f1 = quick_train(model, data, epochs=100, patience=20, verbose=True)\n",
    "    \n",
    "    # Final evaluation\n",
    "    final_f1 = evaluate(model, data, data.test_mask)\n",
    "    \n",
    "    results_k_sensitivity.append({\n",
    "        'K': k,\n",
    "        'F1': final_f1,\n",
    "        'edges': edge_index.shape[1]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n‚úÖ K={k}: Final Test F1 = {final_f1:.4f} ({final_f1*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"K-SENSITIVITY RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_k_results = pd.DataFrame(results_k_sensitivity)\n",
    "print(\"\\n\" + df_k_results.to_string(index=False))\n",
    "\n",
    "# Compute improvement\n",
    "baseline_f1 = df_k_results[df_k_results['K'] == 5]['F1'].values[0]\n",
    "best_k = df_k_results.loc[df_k_results['F1'].idxmax(), 'K']\n",
    "best_f1 = df_k_results['F1'].max()\n",
    "improvement = (best_f1 - baseline_f1) * 100\n",
    "\n",
    "print(f\"\\nüìä Analysis:\")\n",
    "print(f\"   Baseline (K=5):  {baseline_f1:.4f} ({baseline_f1*100:.2f}%)\")\n",
    "print(f\"   Best (K={best_k}):     {best_f1:.4f} ({best_f1*100:.2f}%)\")\n",
    "print(f\"   Improvement:     {improvement:+.2f} pp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376531ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize K-sensitivity\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: K vs F1-Score\n",
    "ax1.plot(df_k_results['K'], df_k_results['F1'], \n",
    "         marker='o', linewidth=3, markersize=10, color='#e74c3c')\n",
    "ax1.axhline(y=0.882, color='blue', linestyle='--', linewidth=2, alpha=0.7, label='MLP Baseline (88.2%)')\n",
    "ax1.axhline(y=0.90, color='green', linestyle='--', linewidth=2, alpha=0.7, label='MAPS Target (90%)')\n",
    "ax1.set_xlabel('K (Number of Neighbors)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Test F1-Score', fontsize=14, fontweight='bold')\n",
    "ax1.set_title('K-Sensitivity: Does Larger K Help?', fontsize=16, fontweight='bold')\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend(fontsize=12)\n",
    "ax1.set_ylim([0.8, 0.95])\n",
    "\n",
    "# Annotate points\n",
    "for _, row in df_k_results.iterrows():\n",
    "    ax1.annotate(f\"{row['F1']:.3f}\", \n",
    "                xy=(row['K'], row['F1']), \n",
    "                xytext=(0, 10), \n",
    "                textcoords='offset points',\n",
    "                ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# Plot 2: K vs Improvement over K=5\n",
    "improvements = [(f1 - baseline_f1) * 100 for f1 in df_k_results['F1']]\n",
    "colors = ['#2ecc71' if imp > 0 else '#e74c3c' for imp in improvements]\n",
    "\n",
    "bars = ax2.bar(df_k_results['K'], improvements, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax2.set_xlabel('K (Number of Neighbors)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Improvement vs K=5 (percentage points)', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('Improvement Over Baseline (K=5)', fontsize=16, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar, imp in zip(bars, improvements):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{imp:+.2f} pp',\n",
    "            ha='center', va='bottom' if height > 0 else 'top', \n",
    "            fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTERPRETATION GUIDE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if improvement > 2.0:\n",
    "    print(\"\\n‚úÖ SIGNIFICANT IMPROVEMENT!\")\n",
    "    print(f\"   K={best_k} improves by {improvement:.2f} pp over K=5\")\n",
    "    print(\"   ‚Üí K WAS the bottleneck!\")\n",
    "    print(\"   ‚Üí Increase K and potentially beat MLP\")\n",
    "    print(f\"   ‚Üí Next: Try K={best_k} with full 500-epoch training\")\n",
    "elif improvement > 0.5:\n",
    "    print(\"\\n‚ö†Ô∏è MODEST IMPROVEMENT\")\n",
    "    print(f\"   K={best_k} improves by {improvement:.2f} pp over K=5\")\n",
    "    print(\"   ‚Üí K helps but not enough\")\n",
    "    print(\"   ‚Üí Try deeper GNN or different architecture\")\n",
    "else:\n",
    "    print(\"\\n‚ùå NO MEANINGFUL IMPROVEMENT\")\n",
    "    print(f\"   Best improvement: {improvement:.2f} pp\")\n",
    "    print(\"   ‚Üí K is NOT the main issue\")\n",
    "    print(\"   ‚Üí Problem is either:\")\n",
    "    print(\"      1. No spatial patterns exist (check visualization above)\")\n",
    "    print(\"      2. GNN architecture is wrong\")\n",
    "    print(\"      3. Need manual spatial features instead\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201f989",
   "metadata": {},
   "source": [
    "# 5. Experiment 3: Random Graph Baseline\n",
    "\n",
    "**Critical Test**: Is the GNN actually using the graph structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33402ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"EXPERIMENT 3: RANDOM GRAPH BASELINE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Use K=15 (middle value from k-sensitivity)\n",
    "k_test = 15\n",
    "print(f\"\\nTesting with K={k_test} neighbors\\n\")\n",
    "\n",
    "# Build TRUE KNN graph\n",
    "print(\"1Ô∏è‚É£ Building TRUE KNN graph...\")\n",
    "nbrs = NearestNeighbors(n_neighbors=k_test + 1, algorithm='ball_tree').fit(coords)\n",
    "distances, indices = nbrs.kneighbors(coords)\n",
    "source_nodes = np.repeat(np.arange(len(df)), k_test)\n",
    "target_nodes = indices[:, 1:].flatten()\n",
    "edge_index_true = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "print(f\"   ‚úÖ {edge_index_true.shape[1]:,} edges\")\n",
    "\n",
    "# Build RANDOM graph (same number of edges)\n",
    "print(\"\\n2Ô∏è‚É£ Building RANDOM graph (same # edges)...\")\n",
    "n_cells = len(df)\n",
    "n_edges = edge_index_true.shape[1]\n",
    "random_sources = np.random.randint(0, n_cells, size=n_edges)\n",
    "random_targets = np.random.randint(0, n_cells, size=n_edges)\n",
    "# Remove self-loops\n",
    "mask = random_sources != random_targets\n",
    "edge_index_random = torch.tensor([random_sources[mask], random_targets[mask]], dtype=torch.long)\n",
    "print(f\"   ‚úÖ {edge_index_random.shape[1]:,} edges\")\n",
    "\n",
    "# NO GRAPH (empty edge index)\n",
    "print(\"\\n3Ô∏è‚É£ Creating NO GRAPH baseline (empty edges)...\")\n",
    "edge_index_empty = torch.tensor([[], []], dtype=torch.long)\n",
    "print(f\"   ‚úÖ 0 edges\")\n",
    "\n",
    "# Train on each graph type\n",
    "graph_types = [\n",
    "    ('True KNN Graph', edge_index_true),\n",
    "    ('Random Graph', edge_index_random),\n",
    "    ('No Graph (Empty)', edge_index_empty),\n",
    "]\n",
    "\n",
    "results_graph_baseline = []\n",
    "\n",
    "for graph_name, edge_index in graph_types:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training with: {graph_name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Create data\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        y=y,\n",
    "        train_mask=train_mask,\n",
    "        test_mask=test_mask\n",
    "    ).to(device)\n",
    "    \n",
    "    # Train\n",
    "    model = GraphSAGE(len(marker_cols), 512, num_classes, dropout=0.1).to(device)\n",
    "    best_f1 = quick_train(model, data, epochs=100, patience=20, verbose=True)\n",
    "    final_f1 = evaluate(model, data, data.test_mask)\n",
    "    \n",
    "    results_graph_baseline.append({\n",
    "        'Graph Type': graph_name,\n",
    "        'F1': final_f1,\n",
    "        'Edges': edge_index.shape[1]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n‚úÖ {graph_name}: Final F1 = {final_f1:.4f} ({final_f1*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GRAPH BASELINE RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "df_graph_results = pd.DataFrame(results_graph_baseline)\n",
    "print(\"\\n\" + df_graph_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3495851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize graph baseline results\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 7))\n",
    "\n",
    "graph_names = df_graph_results['Graph Type'].tolist()\n",
    "f1_scores = df_graph_results['F1'].tolist()\n",
    "colors = ['#2ecc71', '#e67e22', '#e74c3c']\n",
    "\n",
    "bars = ax.bar(graph_names, f1_scores, color=colors, edgecolor='black', linewidth=2, width=0.6)\n",
    "ax.axhline(y=0.882, color='blue', linestyle='--', linewidth=2, label='MLP Baseline (88.2%)')\n",
    "ax.set_ylabel('Test F1-Score', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Graph Structure Test: Is GNN Using the Graph?', fontsize=16, fontweight='bold')\n",
    "ax.set_ylim([0.75, 0.95])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "for bar, f1 in zip(bars, f1_scores):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{f1:.4f}\\n({f1*100:.2f}%)',\n",
    "            ha='center', va='bottom', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretation\n",
    "true_f1 = df_graph_results[df_graph_results['Graph Type'] == 'True KNN Graph']['F1'].values[0]\n",
    "random_f1 = df_graph_results[df_graph_results['Graph Type'] == 'Random Graph']['F1'].values[0]\n",
    "empty_f1 = df_graph_results[df_graph_results['Graph Type'] == 'No Graph (Empty)']['F1'].values[0]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "diff_true_vs_random = (true_f1 - random_f1) * 100\n",
    "diff_true_vs_empty = (true_f1 - empty_f1) * 100\n",
    "\n",
    "print(f\"\\nTrue vs Random: {diff_true_vs_random:+.2f} pp\")\n",
    "print(f\"True vs Empty:  {diff_true_vs_empty:+.2f} pp\")\n",
    "\n",
    "if diff_true_vs_random > 1.0:\n",
    "    print(\"\\n‚úÖ GNN IS USING THE GRAPH!\")\n",
    "    print(\"   True graph >> Random graph\")\n",
    "    print(\"   ‚Üí GNN learns from spatial structure\")\n",
    "    print(\"   ‚Üí Problem is K/architecture, not fundamental\")\n",
    "elif diff_true_vs_random > 0.3:\n",
    "    print(\"\\n‚ö†Ô∏è GNN WEAKLY USES GRAPH\")\n",
    "    print(\"   True graph slightly > Random graph\")\n",
    "    print(\"   ‚Üí GNN uses graph but benefit is small\")\n",
    "    print(\"   ‚Üí Spatial patterns might be weak\")\n",
    "else:\n",
    "    print(\"\\n‚ùå GNN NOT USING GRAPH!\")\n",
    "    print(\"   True graph ‚âà Random graph\")\n",
    "    print(\"   ‚Üí GNN ignores graph structure\")\n",
    "    print(\"   ‚Üí Either:\")\n",
    "    print(\"      1. Implementation bug (message passing not working)\")\n",
    "    print(\"      2. Protein features so strong that graph is redundant\")\n",
    "    print(\"      3. No spatial patterns to learn\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d322e650",
   "metadata": {},
   "source": [
    "# 6. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"DIAGNOSTIC SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"1Ô∏è‚É£ EXPERIMENT 1: K-SENSITIVITY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{df_k_results.to_string(index=False)}\")\n",
    "print(f\"\\n   ‚Üí Best K: {best_k} (F1 = {best_f1:.4f})\")\n",
    "print(f\"   ‚Üí Improvement over K=5: {improvement:+.2f} pp\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2Ô∏è‚É£ EXPERIMENT 2: SPATIAL PATTERNS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n   ‚Üí Check visualization above\")\n",
    "print(\"   ‚Üí Are cell types clustered or random?\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3Ô∏è‚É£ EXPERIMENT 3: GRAPH BASELINE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{df_graph_results.to_string(index=False)}\")\n",
    "print(f\"\\n   ‚Üí True vs Random: {diff_true_vs_random:+.2f} pp\")\n",
    "print(f\"   ‚Üí True vs Empty:  {diff_true_vs_empty:+.2f} pp\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Decision tree based on results\n",
    "if improvement > 2.0 and diff_true_vs_random > 1.0:\n",
    "    print(\"\\nüéâ GOOD NEWS! Both K and graph matter!\")\n",
    "    print(\"\\n‚úÖ NEXT STEPS:\")\n",
    "    print(f\"   1. Use K={best_k} with full 500-epoch training\")\n",
    "    print(\"   2. Try 3-4 layer GNN (deeper receptive field)\")\n",
    "    print(\"   3. Experiment with GAT (attention mechanism)\")\n",
    "    print(\"   4. Expected: Should beat MLP (88.2%) and approach MAPS (90%)\")\n",
    "\n",
    "elif improvement > 0.5:\n",
    "    print(\"\\n‚ö†Ô∏è MIXED RESULTS: K helps modestly\")\n",
    "    print(\"\\n‚úÖ NEXT STEPS:\")\n",
    "    print(f\"   1. Try K={best_k} with deeper GNN (3-4 layers)\")\n",
    "    print(\"   2. Experiment with different architectures (GAT, GCN)\")\n",
    "    print(\"   3. Consider manual spatial features as alternative\")\n",
    "    print(\"   4. Expected: Might reach 85-87%, still below MLP\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ùå BAD NEWS: K doesn't help significantly\")\n",
    "    print(\"\\nüîÑ ALTERNATIVE APPROACHES:\")\n",
    "    print(\"   1. MANUAL SPATIAL FEATURES (recommended):\")\n",
    "    print(\"      - For each cell: avg neighbor expression, cell type composition\")\n",
    "    print(\"      - Add to MLP ‚Üí simpler and might work better\")\n",
    "    print(\"\\n   2. ABANDON SPATIAL CONTEXT:\")\n",
    "    print(\"      - Focus on improving MLP (88.2% ‚Üí 90%)\")\n",
    "    print(\"      - Hyperparameter tuning, ensembles, better features\")\n",
    "    print(\"\\n   3. INVESTIGATE DATA:\")\n",
    "    print(\"      - Compute spatial autocorrelation (Moran's I)\")\n",
    "    print(\"      - If no spatial patterns ‚Üí GNN will never help\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üöÄ DIAGNOSTICS COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüíª Hardware: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"‚è±Ô∏è  Note: Used quick training (100 epochs) for diagnostics\")\n",
    "print(f\"üìä Full training (500 epochs) may show +1-2% improvement\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

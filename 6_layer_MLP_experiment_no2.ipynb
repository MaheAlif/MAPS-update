{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "324a3905",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de90cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n",
      "üìÇ Working directory: c:\\Users\\mahee\\OneDrive\\Documents\\Semester-12\\FYDP-2\\MAPS\\Experiments_my_ideas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "\n",
    "# Add parent directory for MAPS import\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "# Clear cached imports\n",
    "for mod_name in list(sys.modules.keys()):\n",
    "    if 'MAPS' in mod_name or 'maps' in mod_name:\n",
    "        del sys.modules[mod_name]\n",
    "\n",
    "from MAPS.cell_phenotyping import Trainer, Predictor\n",
    "from MAPS.cell_phenotyping.datasets import CellExpressionCSV\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"üìÇ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c45d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è Hardware Check:\n",
      "   CUDA available: True\n",
      "   GPU: NVIDIA GeForce GTX 1650\n",
      "   CUDA version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# Check GPU\n",
    "print(\"üñ•Ô∏è Hardware Check:\")\n",
    "print(f\"   CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA version: {torch.version.cuda}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"   Running on CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb0233a",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Define Custom 6-Layer MLP\n",
    "\n",
    "### Architecture Comparison:\n",
    "\n",
    "**MAPS 4-Layer MLP:**\n",
    "```\n",
    "Input ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Classifier(num_classes)\n",
    "```\n",
    "\n",
    "**Our 6-Layer MLP:**\n",
    "```\n",
    "Input ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout  ‚Üê NEW\n",
    "      ‚Üí Linear(512) ‚Üí ReLU ‚Üí Dropout  ‚Üê NEW\n",
    "      ‚Üí Classifier(num_classes)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdc192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 6-Layer MLP defined!\n",
      "\n",
      "üìä Model Statistics:\n",
      "   Total parameters: 1,347,600\n",
      "\n",
      "   (4-layer MAPS has ~1.3M params, this has more!)\n"
     ]
    }
   ],
   "source": [
    "class MLP_6Layer(nn.Module):\n",
    "    \"\"\"\n",
    "    6-Layer Multi-Layer Perceptron\n",
    "    \n",
    "    Deeper architecture with 6 hidden layers instead of 4.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=50, hidden_dim=512, num_classes=16, dropout=0.10):\n",
    "        super(MLP_6Layer, self).__init__()\n",
    "        \n",
    "        # 6 hidden layers\n",
    "        self.fc = nn.Sequential(\n",
    "            # Layer 1\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # Layer 2\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # Layer 3\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # Layer 4\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # Layer 5 (NEW)\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout),\n",
    "            \n",
    "            # Layer 6 (NEW)\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout)\n",
    "        )\n",
    "        \n",
    "        # Output classifier\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        \n",
    "        Args:\n",
    "            batch: Input tensor of shape (batch_size, input_dim)\n",
    "        \n",
    "        Returns:\n",
    "            logits: Raw output scores\n",
    "            probs: Softmax probabilities\n",
    "        \"\"\"\n",
    "        features = self.fc(batch)\n",
    "        logits = self.classifier(features)\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        return logits, probs\n",
    "\n",
    "print(\"‚úÖ 6-Layer MLP defined!\")\n",
    "\n",
    "# Test instantiation\n",
    "test_model = MLP_6Layer(input_dim=50, hidden_dim=512, num_classes=16, dropout=0.10)\n",
    "total_params = sum(p.numel() for p in test_model.parameters())\n",
    "print(f\"\\nüìä Model Statistics:\")\n",
    "print(f\"   Total parameters: {total_params:,}\")\n",
    "print(f\"\\n   (4-layer MAPS has ~1.3M params, this has more!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d14fc",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ca4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Found preprocessed data!\n",
      "\n",
      "üìä Dataset Info:\n",
      "   Training samples: 114,984\n",
      "   Features: 50\n",
      "   Classes: 16\n",
      "\n",
      "   Class names: B, CD4, CD8, DC, Endothelial, Epithelial, Lymphatic, M1, M2, Mast, Monocyte, NK, Neutrophil, Other, TReg, Tumor\n"
     ]
    }
   ],
   "source": [
    "# Use the data preprocessed from previous notebook\n",
    "data_dir = './cHL_CODEX_processed'\n",
    "train_path = os.path.join(data_dir, 'train.csv')\n",
    "valid_path = os.path.join(data_dir, 'valid.csv')\n",
    "class_path = os.path.join(data_dir, 'class_names.csv')\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(train_path):\n",
    "    print(\"‚ùå Preprocessed data not found!\")\n",
    "    print(\"   Please run 'cHL_CODEX_training_comparison.ipynb' first to generate the data.\")\n",
    "else:\n",
    "    print(\"‚úÖ Found preprocessed data!\")\n",
    "    \n",
    "    # Load class info\n",
    "    class_df = pd.read_csv(class_path)\n",
    "    NUM_CLASSES = len(class_df)\n",
    "    \n",
    "    # Load to check dimensions\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    NUM_FEATURES = len(train_df.columns) - 1  # Exclude 'cell_label'\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Info:\")\n",
    "    print(f\"   Training samples: {len(train_df):,}\")\n",
    "    print(f\"   Features: {NUM_FEATURES}\")\n",
    "    print(f\"   Classes: {NUM_CLASSES}\")\n",
    "    print(f\"\\n   Class names: {', '.join(class_df['class_name'].tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7022de",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Custom Training Loop for 6-Layer MLP\n",
    "\n",
    "Since we're using a custom architecture, we need a custom training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0daeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Training Configuration:\n",
      "   Batch size: 512\n",
      "   Learning rate: 0.001\n",
      "   Dropout: 0.1\n",
      "   Max epochs: 100\n",
      "   Patience: 20\n",
      "   Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "BATCH_SIZE = 512 if torch.cuda.is_available() else 128\n",
    "LEARNING_RATE = 0.001\n",
    "DROPOUT = 0.10\n",
    "MAX_EPOCHS = 100\n",
    "MIN_EPOCHS = 20\n",
    "PATIENCE = 20\n",
    "SEED = 42\n",
    "\n",
    "print(\"‚öôÔ∏è Training Configuration:\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   Dropout: {DROPOUT}\")\n",
    "print(f\"   Max epochs: {MAX_EPOCHS}\")\n",
    "print(f\"   Patience: {PATIENCE}\")\n",
    "print(f\"   Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ff7533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Seeds set for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "import random\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"‚úÖ Seeds set for reproducibility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82074a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading datasets...\n",
      "‚úÖ Data loaded!\n",
      "   Train batches: 224\n",
      "   Valid batches: 57\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "print(\"üìÇ Loading datasets...\")\n",
    "\n",
    "train_dataset = CellExpressionCSV(train_path, is_train=True)\n",
    "valid_dataset = CellExpressionCSV(valid_path, is_train=False, \n",
    "                                  mean=train_dataset.mean, \n",
    "                                  std=train_dataset.std)\n",
    "\n",
    "train_loader = CellExpressionCSV.get_data_loader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                                                  is_train=True, num_workers=4 if torch.cuda.is_available() else 0)\n",
    "valid_loader = CellExpressionCSV.get_data_loader(valid_dataset, batch_size=BATCH_SIZE, \n",
    "                                                  is_train=False, num_workers=4 if torch.cuda.is_available() else 0)\n",
    "\n",
    "print(f\"‚úÖ Data loaded!\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Valid batches: {len(valid_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fece690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing 6-Layer MLP...\n",
      "‚úÖ Model initialized!\n",
      "   Parameters: 1,347,600\n",
      "   Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "print(\"üöÄ Initializing 6-Layer MLP...\")\n",
    "\n",
    "model = MLP_6Layer(input_dim=NUM_FEATURES, hidden_dim=512, \n",
    "                   num_classes=NUM_CLASSES, dropout=DROPOUT)\n",
    "model.to(device, dtype=torch.float64)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(\"‚úÖ Model initialized!\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"   Device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b552df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for features, labels in loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits, probs = model(features)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            logits, probs = model(features)\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy, all_preds, all_labels\n",
    "\n",
    "print(\"‚úÖ Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6134da6",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Train the 6-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889f44f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING 6-LAYER MLP\n",
      "============================================================\n",
      "Epoch   1/100 | Train Loss: 2.4323 Acc: 0.1515 | Valid Loss: 2.1758 Acc: 0.2343 | Time: 48.1s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 2.1758)\n",
      "Epoch   2/100 | Train Loss: 1.6592 Acc: 0.4250 | Valid Loss: 1.4830 Acc: 0.4708 | Time: 44.8s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 1.4830)\n",
      "Epoch   3/100 | Train Loss: 1.0859 Acc: 0.6524 | Valid Loss: 1.2219 Acc: 0.5892 | Time: 46.7s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 1.2219)\n",
      "Epoch   4/100 | Train Loss: 0.9274 Acc: 0.7087 | Valid Loss: 1.0693 Acc: 0.6444 | Time: 47.4s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 1.0693)\n",
      "Epoch   5/100 | Train Loss: 0.8178 Acc: 0.7434 | Valid Loss: 0.8966 Acc: 0.7027 | Time: 45.2s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 0.8966)\n",
      "Epoch   6/100 | Train Loss: 0.7249 Acc: 0.7734 | Valid Loss: 0.9113 Acc: 0.7071 | Time: 45.2s\n",
      "Epoch   7/100 | Train Loss: 0.6642 Acc: 0.7926 | Valid Loss: 0.7626 Acc: 0.7539 | Time: 46.2s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 0.7626)\n",
      "Epoch   8/100 | Train Loss: 0.6339 Acc: 0.8009 | Valid Loss: 0.7422 Acc: 0.7575 | Time: 45.7s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 0.7422)\n",
      "Epoch   9/100 | Train Loss: 0.5945 Acc: 0.8118 | Valid Loss: 0.7240 Acc: 0.7618 | Time: 49.5s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 0.7240)\n",
      "Epoch  10/100 | Train Loss: 0.5661 Acc: 0.8198 | Valid Loss: 0.7014 Acc: 0.7656 | Time: 48.4s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 0.7014)\n",
      "Epoch  11/100 | Train Loss: 0.5401 Acc: 0.8252 | Valid Loss: 0.6527 Acc: 0.7784 | Time: 47.0s\n",
      "  ‚Üí üíæ Saved best model (valid_loss: 0.6527)\n",
      "Epoch  12/100 | Train Loss: 0.5230 Acc: 0.8315 | Valid Loss: 0.6745 Acc: 0.7704 | Time: 42.8s\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING 6-LAYER MLP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Training tracking\n",
    "results_dir = './results_6layer_model/'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'valid_loss': [], 'valid_acc': []\n",
    "}\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "patience_counter = 0\n",
    "best_model_path = os.path.join(results_dir, 'best_6layer_model.pt')\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    valid_loss, valid_acc, _, _ = validate_epoch(model, valid_loader, criterion, device)\n",
    "    \n",
    "    # Record\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['valid_loss'].append(valid_loss)\n",
    "    history['valid_acc'].append(valid_acc)\n",
    "    \n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1:3d}/{MAX_EPOCHS} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | \"\n",
    "          f\"Valid Loss: {valid_loss:.4f} Acc: {valid_acc:.4f} | \"\n",
    "          f\"Time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        patience_counter = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_mean': train_dataset.mean,\n",
    "            'train_std': train_dataset.std,\n",
    "            'valid_loss': valid_loss,\n",
    "            'valid_acc': valid_acc\n",
    "        }, best_model_path)\n",
    "        print(f\"  ‚Üí üíæ Saved best model (valid_loss: {valid_loss:.4f})\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= PATIENCE and epoch >= MIN_EPOCHS:\n",
    "            print(f\"\\n‚èπÔ∏è  Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n‚è±Ô∏è  Total time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"üìä Epochs: {len(history['train_loss'])}\")\n",
    "print(f\"üéØ Best valid loss: {best_valid_loss:.4f}\")\n",
    "\n",
    "# Save training history\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(os.path.join(results_dir, 'training_logs.csv'), index=False)\n",
    "print(f\"üíæ Training logs saved to: {results_dir}training_logs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109d808",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs, history['train_loss'], 'b-', label='Training', linewidth=2)\n",
    "axes[0].plot(epochs, history['valid_loss'], 'r-', label='Validation', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('6-Layer MLP: Training vs Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs, history['train_acc'], 'b-', label='Training', linewidth=2)\n",
    "axes[1].plot(epochs, history['valid_acc'], 'r-', label='Validation', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[1].set_title('6-Layer MLP: Training vs Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Training Summary:\")\n",
    "print(f\"   Final train accuracy: {history['train_acc'][-1]:.4f}\")\n",
    "print(f\"   Final valid accuracy: {history['valid_acc'][-1]:.4f}\")\n",
    "print(f\"   Best valid accuracy: {max(history['valid_acc']):.4f}\")\n",
    "print(f\"   Time per epoch: {training_time/len(epochs):.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c05bf4",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 7: Evaluate 6-Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "print(\"üì¶ Loading best 6-layer model...\")\n",
    "checkpoint = torch.load(best_model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Loaded model from epoch {checkpoint['epoch']+1}\")\n",
    "print(f\"   Valid loss: {checkpoint['valid_loss']:.4f}\")\n",
    "print(f\"   Valid acc: {checkpoint['valid_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07937000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "print(\"\\nüîÆ Making predictions...\")\n",
    "_, _, pred_labels_6layer, gt_labels = validate_epoch(model, valid_loader, criterion, device)\n",
    "\n",
    "accuracy_6layer = accuracy_score(gt_labels, pred_labels_6layer)\n",
    "print(f\"\\nüéØ 6-LAYER MODEL ACCURACY: {accuracy_6layer:.4f} ({accuracy_6layer*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c833921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT (6-Layer Model):\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(gt_labels, pred_labels_6layer, \n",
    "                          target_names=class_df['class_name'].tolist(), \n",
    "                          digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b83183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_6layer = confusion_matrix(gt_labels, pred_labels_6layer)\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(cm_6layer, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=class_df['class_name'].tolist(),\n",
    "            yticklabels=class_df['class_name'].tolist())\n",
    "plt.title('Confusion Matrix - 6-Layer MLP', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4058d5",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 8: Compare with 4-Layer and Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1de6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results from previous 4-layer experiment\n",
    "prev_results_path = './results_new_model/training_logs.csv'\n",
    "\n",
    "if os.path.exists(prev_results_path):\n",
    "    print(\"üìä Loading 4-layer model results...\")\n",
    "    \n",
    "    # Train 4-layer predictor to get accuracy\n",
    "    trainer_4layer = Trainer(\n",
    "        model_checkpoint_path='./results_new_model/best_checkpoint.pt',\n",
    "        results_dir='./results_new_model/',\n",
    "        num_features=NUM_FEATURES,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    pred_labels_4layer, _ = trainer_4layer.predict(valid_path)\n",
    "    accuracy_4layer = accuracy_score(gt_labels, pred_labels_4layer)\n",
    "    \n",
    "    print(f\"‚úÖ 4-layer model accuracy: {accuracy_4layer:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è 4-layer model results not found. Run the previous notebook first.\")\n",
    "    accuracy_4layer = None\n",
    "    pred_labels_4layer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a62e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MAPS pretrained model\n",
    "pretrained_path = '../models/cell_phenotyping/cHL_CODEX.pt'\n",
    "\n",
    "if os.path.exists(pretrained_path):\n",
    "    print(\"üì¶ Loading MAPS pretrained model...\")\n",
    "    \n",
    "    pretrained_predictor = Predictor(\n",
    "        model_checkpoint_path=pretrained_path,\n",
    "        num_features=NUM_FEATURES,\n",
    "        num_classes=NUM_CLASSES,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    pred_labels_pretrained, _ = pretrained_predictor.predict(valid_path)\n",
    "    accuracy_pretrained = accuracy_score(gt_labels, pred_labels_pretrained)\n",
    "    \n",
    "    print(f\"‚úÖ Pretrained model accuracy: {accuracy_pretrained:.4f}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pretrained model not found.\")\n",
    "    accuracy_pretrained = None\n",
    "    pred_labels_pretrained = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüÜï 6-Layer MLP (your model):         {accuracy_6layer:.4f} ({accuracy_6layer*100:.2f}%)\")\n",
    "\n",
    "if accuracy_4layer is not None:\n",
    "    print(f\"üìä 4-Layer MLP (standard MAPS):      {accuracy_4layer:.4f} ({accuracy_4layer*100:.2f}%)\")\n",
    "    print(f\"   ‚Üí Difference (6L vs 4L): {(accuracy_6layer - accuracy_4layer)*100:+.2f}%\")\n",
    "\n",
    "if accuracy_pretrained is not None:\n",
    "    print(f\"üì¶ Pretrained MAPS (500 epochs):     {accuracy_pretrained:.4f} ({accuracy_pretrained*100:.2f}%)\")\n",
    "    print(f\"   ‚Üí Difference (6L vs pretrained): {(accuracy_6layer - accuracy_pretrained)*100:+.2f}%\")\n",
    "\n",
    "print(\"\\nüìà Analysis:\")\n",
    "if accuracy_4layer is not None:\n",
    "    if accuracy_6layer > accuracy_4layer:\n",
    "        print(\"   ‚úÖ The deeper 6-layer architecture performs BETTER!\")\n",
    "        print(\"   üí° More layers helped capture complex patterns.\")\n",
    "    elif accuracy_6layer > accuracy_4layer - 0.01:\n",
    "        print(\"   ‚öñÔ∏è  Both architectures perform similarly.\")\n",
    "        print(\"   üí° Adding layers didn't hurt, but didn't help much either.\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è The 4-layer model performed slightly better.\")\n",
    "        print(\"   üí° Deeper isn't always better - may need more regularization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b72e88",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 9: Per-Class Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b7eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate F1 scores per class\n",
    "if accuracy_4layer is not None:\n",
    "    print(\"\\nüìä PER-CLASS F1 SCORE COMPARISON:\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    comparison_data = []\n",
    "    for i, class_name in enumerate(class_df['class_name']):\n",
    "        gt_binary = (np.array(gt_labels) == i).astype(int)\n",
    "        \n",
    "        pred_6l_binary = (np.array(pred_labels_6layer) == i).astype(int)\n",
    "        f1_6layer = f1_score(gt_binary, pred_6l_binary, zero_division=0)\n",
    "        \n",
    "        pred_4l_binary = (np.array(pred_labels_4layer) == i).astype(int)\n",
    "        f1_4layer = f1_score(gt_binary, pred_4l_binary, zero_division=0)\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'Class': class_name,\n",
    "            'Count': (np.array(gt_labels) == i).sum(),\n",
    "            '6-Layer F1': f1_6layer,\n",
    "            '4-Layer F1': f1_4layer,\n",
    "            'Improvement': f1_6layer - f1_4layer\n",
    "        })\n",
    "    \n",
    "    comp_df = pd.DataFrame(comparison_data)\n",
    "    comp_df = comp_df.sort_values('Improvement', ascending=False)\n",
    "    \n",
    "    print(comp_df.to_string(index=False, float_format=lambda x: f\"{x:.3f}\"))\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    x = np.arange(len(comp_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, comp_df['6-Layer F1'], width, label='6-Layer MLP', alpha=0.8, color='green')\n",
    "    bars2 = plt.bar(x + width/2, comp_df['4-Layer F1'], width, label='4-Layer MLP', alpha=0.8, color='blue')\n",
    "    \n",
    "    plt.xlabel('Cell Type', fontsize=12)\n",
    "    plt.ylabel('F1 Score', fontsize=12)\n",
    "    plt.title('Per-Class Performance: 6-Layer vs 4-Layer MLP', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(x, comp_df['Class'], rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Highlight improvements\n",
    "    improvements = comp_df[comp_df['Improvement'] > 0.02]\n",
    "    if len(improvements) > 0:\n",
    "        print(\"\\nüéâ Classes where 6-layer improves significantly:\")\n",
    "        for _, row in improvements.iterrows():\n",
    "            print(f\"   {row['Class']}: +{row['Improvement']:.3f}\")\n",
    "    \n",
    "    degradations = comp_df[comp_df['Improvement'] < -0.02]\n",
    "    if len(degradations) > 0:\n",
    "        print(\"\\n‚ö†Ô∏è Classes where 6-layer performs worse:\")\n",
    "        for _, row in degradations.iterrows():\n",
    "            print(f\"   {row['Class']}: {row['Improvement']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ce8af",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 10: Final Summary & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a5bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÅ EXPERIMENT SUMMARY: 6-LAYER MLP\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüèóÔ∏è Architecture:\")\n",
    "print(f\"   Layers: 6 hidden layers (vs 4 in standard MAPS)\")\n",
    "print(f\"   Hidden units: 512 per layer\")\n",
    "print(f\"   Dropout: {DROPOUT}\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Training:\")\n",
    "print(f\"   Time: {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
    "print(f\"   Epochs: {len(history['train_loss'])}\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "\n",
    "print(f\"\\nüéØ Performance:\")\n",
    "print(f\"   6-Layer MLP: {accuracy_6layer:.4f} ({accuracy_6layer*100:.2f}%)\")\n",
    "if accuracy_4layer is not None:\n",
    "    print(f\"   4-Layer MLP: {accuracy_4layer:.4f} ({accuracy_4layer*100:.2f}%)\")\n",
    "    print(f\"   Improvement: {(accuracy_6layer - accuracy_4layer)*100:+.2f}%\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Files:\")\n",
    "print(f\"   Model: {best_model_path}\")\n",
    "print(f\"   Logs: {results_dir}training_logs.csv\")\n",
    "\n",
    "print(\"\\nüî¨ Conclusions:\")\n",
    "if accuracy_4layer is not None:\n",
    "    diff = accuracy_6layer - accuracy_4layer\n",
    "    if diff > 0.01:\n",
    "        print(\"   ‚úÖ Deeper architecture (6 layers) provides measurable improvement\")\n",
    "        print(\"   üí° Consider trying even deeper networks (8 layers?)\")\n",
    "    elif diff > -0.01:\n",
    "        print(\"   ‚öñÔ∏è  Performance is comparable - depth didn't significantly help\")\n",
    "        print(\"   üí° 4 layers may be sufficient for this task\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Deeper network underperformed slightly\")\n",
    "        print(\"   üí° May need different hyperparameters (learning rate, dropout)\")\n",
    "\n",
    "print(\"\\nüí° Next Experiments to Try:\")\n",
    "print(\"   1. Try 8-layer MLP (go even deeper)\")\n",
    "print(\"   2. Try different hidden dimensions (256, 768, 1024)\")\n",
    "print(\"   3. Try different dropout rates (0.05, 0.15, 0.20)\")\n",
    "print(\"   4. Try batch normalization between layers\")\n",
    "print(\"   5. Try residual connections (ResNet-style)\")\n",
    "print(\"   6. Try different activation functions (LeakyReLU, ELU)\")\n",
    "\n",
    "print(\"\\n‚úÖ Experiment complete!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

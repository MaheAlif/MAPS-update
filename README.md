"# MAPS-update" 
"# MAPS-update" 
"# GNN-Enhanced Cell Type Classification

## üéØ Project Goal
Beat the MAPS baseline (90% F1) by incorporating **Graph Neural Networks (GNNs)** to leverage spatial neighborhood information in cell phenotyping.

**Hypothesis**: Cells of the same type cluster together in tissue. GNNs should learn from this spatial context and outperform protein-only MLPs.

---

## üìä Dataset
- **Source**: cHL_CODEX annotated dataset
- **Size**: 100,814 cells
- **Features**: 49 protein markers + X/Y coordinates
- **Labels**: 14 cell types
- **Baseline**: MAPS MLP achieves 90% F1 (random 80/20 split)

---

## üß™ Experiments Conducted

### Experiment 1: Initial GNN Implementation
**Notebook**: `gnn-maps-3.ipynb`

**Configuration**:
- MLP: 4 hidden layers (512 units), 500 epochs, dropout=0.1
- GNN: 2-layer GraphSAGE (512 hidden), K=5 neighbors, 500 epochs
- Split: Spatial (X-axis 80/20) to prevent data leakage

**Results**:
- MLP: **86.9%** F1
- GNN: **82.2%** F1 ‚ùå

**Diagnosis**: Spatial split causes distribution shift. GNN overfits to training region topology.

---

### Experiment 2: Random Split (Eliminate Distribution Shift)
**Notebook**: `gnn-maps-4-randSplit.ipynb`

**Configuration**:
- Random 80/20 split (matches MAPS methodology)
- Same MLP/GNN architecture as Experiment 1

**Results**:
- MLP: **88.2%** F1 ‚úÖ (close to MAPS 90%)
- GNN: **83.6%** F1 ‚ùå

**Diagnosis**: Distribution shift was NOT the issue. GNN still underperforms by 4.6 pp.

---

### Experiment 3: Hybrid Model (Protein + Spatial Features)
**Notebook**: `gnn-maps-5-protein&spatialfeatures.ipynb`

**Configuration**:
- MLP branch: Processes protein markers
- GNN branch: Processes protein + graph structure
- Hybrid: Concatenates both embeddings
- Random 80/20 split

**Results**:
- MLP: **86.7%** F1
- GNN: **82.1%** F1
- Hybrid: **86.5%** F1 ‚ùå

**Diagnosis**: Hybrid ‚âà MLP. GNN features contribute NOTHING. Model learns to ignore spatial branch.

---

### Experiment 4: 5-Fold Spatial Cross-Validation
**Notebook**: `gnn-maps-6-spatialCV.ipynb`

**Configuration**:
- 5-fold spatial cross-validation (test all regions)
- MLP: Random 80/20 (baseline)
- GNN: 5 different spatial folds

**Results**:
- MLP (random): **88.2%** F1
- GNN (5-fold mean): **83.2% ¬± 0.74%** F1 ‚ùå
  - Fold 1: 82.3%
  - Fold 2: 83.4%
  - Fold 3: 82.5%
  - Fold 4: 84.3%
  - Fold 5: 83.6%

**Diagnosis**: 
- Low variance (0.74%) = stable performance
- ALL folds underperform MLP by ~5 pp
- **This is NOT variance/luck‚Äîit's architectural failure**

---

## üî¨ Experiment 5: Diagnostic Experiments ‚ùå DEVASTATING RESULTS
**Notebook**: `gnn-maps-7-diagnostics.ipynb` ‚úÖ **COMPLETED**

**Goal**: Determine WHY GNN consistently underperforms MLP by ~5 percentage points

### Three Diagnostic Tests Conducted:

#### 1. **K-Sensitivity Analysis** ‚≠ê
**Hypothesis**: K=5 neighbors is too small for 145K cell dataset

**Results**:
| K | Test F1 | Edges | Improvement |
|---|---------|-------|-------------|
| 5 | 77.53% | 725,805 | Baseline |
| 10 | 77.52% | 1,451,610 | -0.01 pp |
| 15 | 77.16% | 2,177,415 | -0.37 pp |
| 20 | 77.59% | 2,903,220 | **+0.06 pp** |
| 25 | 77.51% | 3,629,025 | -0.02 pp |

**Finding**: ‚ùå **K IS NOT THE ISSUE**
- Best improvement: Only +0.06 percentage points (K=20)
- Performance essentially FLAT across all K values (77.2-77.6%)
- GNN scores 77.5% vs MLP 88.2% = **10.7 pp gap!**
- Increasing receptive field does NOT help

#### 2. **Spatial Pattern Visualization**
**Analysis**: Visualized all 18 cell types in X-Y coordinates
![alt text](image.png)

**Cell Types Observed**:
- CD4 (37,480 cells, 25.8%) - Largest population
- CD8, B cells, DC, Endothelial, Tumor, NK, M2, Monocyte, etc.

**Finding**: ‚úÖ **CLEAR SPATIAL CLUSTERING EXISTS**
- CD4, CD8: Form distinct lymphoid aggregates
- Endothelial: Lines vascular structures
- Tumor cells: Concentrated in specific regions
- Macrophages (M1/M2): Distributed around tumor boundaries
- **Spatial patterns ARE present** ‚Üí GNN SHOULD work but doesn't!

#### 3. **Random Graph Baseline**
**Test**: Compare GNN with True KNN vs Random graph vs No graph

**Results** (K=15):
| Graph Type | Test F1 | Analysis |
|------------|---------|----------|
| True KNN Graph | 77.59% | Baseline |
| Random Graph | 77.55% | -0.04 pp |
| **No Graph (Empty)** | **77.84%** | **+0.25 pp BETTER!** |

**Finding**: ‚ùå **CATASTROPHIC: GNN NOT USING GRAPH STRUCTURE**
- True graph ‚âà Random graph (only 0.04 pp difference)
- **No graph BEATS true graph by 0.25 pp!**
- Graph structure is **ACTIVELY HARMFUL** to performance
- GNN is learning from proteins alone, ignoring spatial context

---

### üî• Diagnostic Summary: THE SMOKING GUN

**Three converging lines of evidence prove GNN failure**:

1. **K-sensitivity flat** ‚Üí Receptive field size irrelevant
2. **Spatial patterns exist** ‚Üí Data supports spatial learning
3. **Random ‚âà True graph** ‚Üí GNN ignores graph structure

**Root Cause Identified**:
- GraphSAGE message passing is **NOT learning useful spatial features**
- Protein expression features so strong they dominate gradient flow
- Spatial aggregation adds noise rather than signal
- GNN effectively degenerates to a worse MLP (77.5% vs 88.2%)

---

## üìà Summary of Results

| Experiment | MLP F1 | GNN F1 | Gap | Status |
|------------|--------|--------|-----|--------|
| Spatial Split (Exp 1) | 86.9% | 82.2% | -4.7 pp | ‚ùå |
| Random Split (Exp 2) | 88.2% | 83.6% | -4.6 pp | ‚ùå |
| Hybrid Model (Exp 3) | 86.7% | 82.1% / 86.5% (hybrid) | -4.6 pp | ‚ùå |
| 5-Fold CV (Exp 4) | 88.2% | 83.2% ¬± 0.74% | -5.0 pp | ‚ùå |
| **Diagnostics (Exp 5)** | **88.2%** | **77.5%** | **-10.7 pp** | ‚ùåüíÄ |
| **MAPS Baseline** | **90.0%** | ‚Äî | ‚Äî | üéØ |

---

## üîç Root Cause Analysis

### ‚ùå CONFIRMED: GNN Architecture Fundamentally Broken

**Five experiments, one conclusion**: Current GraphSAGE implementation **cannot** leverage spatial information.

### Evidence Chain:

1. **Spatial patterns exist** (Exp 5, Visualization)
   - Clear clustering of CD4, CD8, Tumor, Endothelial cells
   - Not a data problem
   
2. **Random graph ‚âà True graph** (Exp 5, Baseline test)
   - True: 77.59%, Random: 77.55%, Empty: 77.84%
   - **Graph structure ignored or harmful**
   
3. **K doesn't matter** (Exp 5, K-sensitivity)
   - K=5 to K=25: Performance flat (77.2%-77.6%)
   - Receptive field size irrelevant
   
4. **Hybrid model fails** (Exp 3)
   - GNN features contribute nothing
   - Model learns to zero out spatial branch
   
5. **Consistent across all splits** (Exp 1-4)
   - Spatial: GNN 82.2% vs MLP 86.9%
   - Random: GNN 83.6% vs MLP 88.2%
   - 5-fold CV: GNN 83.2% vs MLP 88.2%

### Why GNN Fails:

**Primary Issue**: Protein expression features dominate gradients
- 49 protein markers provide strong discriminative signal
- GNN message passing adds noise rather than useful context
- Spatial aggregation dilutes cell-specific protein signatures
- Mean aggregation in GraphSAGE averages away unique cell identities

**Secondary Issues**:
1. GraphSAGE architecture poor fit for this task
2. 2-layer depth insufficient for complex spatial patterns
3. No attention mechanism to weight important neighbors
4. KNN graph might not capture biological neighborhoods

---

## üöÄ Next Steps

### ‚ö†Ô∏è REALITY CHECK: Can We Beat MAPS 90%?

**Short Answer**: **Unlikely with current GNN approach**

**Evidence Against GNN Success**:
- 5 experiments, 0 improvements
- Diagnostics show GNN doesn't use graph (Random ‚âà True ‚âà Empty)
- Spatial patterns exist but GNN can't learn them
- Best GNN: 83.6% (random split) vs MAPS 90% = **6.4 pp gap**
- MLP alone: 88.2% vs MAPS 90% = **1.8 pp gap** (much closer!)

### Three Paths Forward:

#### Path A: **Abandon GNN, Optimize MLP** ‚≠ê RECOMMENDED
**Why**: MLP already at 88.2%, only 1.8 pp from MAPS target
**Actions**:
1. Hyperparameter tuning (learning rate, dropout, layer sizes)
2. Ensemble methods (bagging, boosting)
3. Better data preprocessing
4. Class weighting for rare cell types
5. Focal loss for hard examples
**Expected**: 88.2% ‚Üí 90% achievable with optimization
**Timeline**: 1-2 weeks
**Probability of success**: 70-80%

#### Path B: **Manual Spatial Features + MLP** ‚≠ê WORTH TRYING
**Why**: Spatial patterns exist; GNN can't capture them but manual features might
**Actions**:
1. For each cell, compute:
   - Average neighbor protein expression (K=10, 15, 20)
   - Local cell type composition (% of each type in neighborhood)
   - Distance to nearest tumor/vessel/structure
   - Local density metrics
2. Concatenate with protein markers ‚Üí Feed to MLP
3. Compare: MLP alone vs MLP+spatial
**Expected**: Could reach 89-91% if spatial features informative
**Timeline**: 1 week
**Probability of success**: 40-50%

#### Path C: **Radically Different GNN** (High Risk)
**Why**: Current GraphSAGE provably broken; try fundamentally different approach
**Actions**:
1. **Graph Attention Networks (GAT)** ‚Üí Learn which neighbors matter
2. **Graph Isomorphism Networks (GIN)** ‚Üí More expressive aggregation
3. **Positional encoding** ‚Üí Explicitly encode X-Y coordinates
4. **Hierarchical graphs** ‚Üí Multi-scale neighborhoods
5. **Pre-training** ‚Üí Self-supervised learning on unlabeled data
**Expected**: Uncertain; might still face gradient domination issue
**Timeline**: 2-3 weeks
**Probability of success**: 20-30%

---

### üí° Recommended Action Plan:

**Phase 1 (Week 1)**: Manual Spatial Features
- Implement neighbor aggregation features
- Quick experiment: Does spatial context help MLP?
- If yes ‚Üí Feature engineering is viable path
- If no ‚Üí Confirms spatial info not useful for this task

**Phase 2 (Week 2)**: MLP Optimization
- Hyperparameter sweep (learning rate, batch size, architecture)
- Ensemble 3-5 MLPs with different initializations
- Class balancing and focal loss
- **Goal**: Reach 90% F1

**Phase 3 (Optional)**: Report Findings
- Negative result is still valuable!
- "Why GNN Failed: Gradient Domination in Protein-Rich Cell Phenotyping"
- Lessons: Protein features too strong for naive spatial aggregation

---

## üìÅ Files in This Repository

### Notebooks:
- `gnn-maps-3.ipynb` ‚Äî Initial GNN (spatial split, MAPS-exact config)
- `gnn-maps-4-randSplit.ipynb` ‚Äî Random split experiment
- `gnn-maps-5-protein&spatialfeatures.ipynb` ‚Äî Hybrid model experiment
- `gnn-maps-6-spatialCV.ipynb` ‚Äî 5-fold spatial cross-validation
- `gnn-maps-7-diagnostics.ipynb` ‚Äî **‚úÖ COMPLETED** Diagnostic experiments (K-sensitivity, visualization, baselines)

### Older Experiments:
- `6_layer_MLP_experiment.ipynb` ‚Äî Early MLP architecture tests
- `6_layer_MLP_experiment_no2.ipynb` ‚Äî MLP variations
- `8_layer_MLP_experiment.ipynb` ‚Äî Deeper MLP test
- `cHL_CODEX_training_comparison.ipynb` ‚Äî Training comparisons
- `spatial_features_MLP.ipynb` ‚Äî Manual spatial feature exploration

### Data:
- `cHL_CODEX_processed/` ‚Äî Preprocessed training/validation data
- `cHL_CODEX_spatial_features/` ‚Äî Spatial feature engineering
- `results_*/` ‚Äî Saved models and training logs

### Analysis:
- `FINAL_COMPARISON.md` ‚Äî Comprehensive analysis of Experiments 1-4

---

## üõ†Ô∏è Hardware
- **Platform**: Kaggle Notebooks
- **GPU**: Tesla P100-PCIE-16GB (16GB VRAM)
- **Framework**: PyTorch 2.0+ with PyTorch Geometric

---

## üéì Key Learnings

1. **Data leakage matters**: KNN graphs create spatial dependencies ‚Üí spatial splits prevent leakage
2. **Random split ‚â† solution**: Even with random split, GNN underperforms
3. **Hybrid models reveal feature importance**: When hybrid ‚âà MLP, GNN features are redundant
4. **Low variance = stable failure**: 5-fold CV shows GNN consistently learns wrong patterns
5. **K is NOT critical** ‚ùå: Diagnostics prove K=5 to K=25 makes NO difference
6. **Graph structure ignored** ‚ùå: Random graph ‚âà True graph ‚Üí GNN doesn't use spatial info
7. **Protein features too strong** ‚≠ê: Gradient domination prevents spatial learning
8. **Spatial patterns exist but GNN can't use them** üíî: Visualization shows clear clustering but GNN fails to leverage it
9. **No graph beats graph** ü§Ø: Empty edge index performs BETTER than KNN graph
10. **Beating 90% MAPS unlikely with GNN**: MLP (88.2%) is closer to target than any GNN variant

---

## üìö References
- **MAPS Paper**: [Original methodology for cell phenotyping](https://www.nature.com/articles/s41467-023-44188-w.pdf)
- **GraphSAGE**: Hamilton et al., "Inductive Representation Learning on Large Graphs"
- **PyTorch Geometric**: Fey & Lenssen, "Fast Graph Representation Learning with PyTorch Geometric"

---

## üë§ Author
A. M. Shahriar Rashid Mahe
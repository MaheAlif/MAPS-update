{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f85fafe8",
   "metadata": {},
   "source": [
    "# GNN-MAPS: Hybrid Model (Protein + Spatial Features)\n",
    "\n",
    "**Option 3: Hybrid MLP+GNN Architecture**\n",
    "\n",
    "This notebook implements a **hybrid model** that combines:\n",
    "- ‚úÖ **MLP branch**: Learns from protein markers (like MAPS)\n",
    "- ‚úÖ **GNN branch**: Learns from spatial neighborhood context\n",
    "- ‚úÖ **Fusion**: Concatenates both representations for classification\n",
    "\n",
    "## Hypothesis:\n",
    "Combining protein features AND spatial context should give the best of both worlds!\n",
    "\n",
    "## Expected Results:\n",
    "- Better than pure MLP (adds spatial context)\n",
    "- Better than pure GNN (protein features are strong)\n",
    "- Should handle spatial split better than pure GNN\n",
    "\n",
    "## Configuration:\n",
    "- **Hidden Dimension:** 512 (matches MAPS)\n",
    "- **MLP Branch:** 4 layers (MAPS architecture)\n",
    "- **GNN Branch:** 2 GraphSAGE layers\n",
    "- **Fusion:** Concatenate [MLP features + GNN features]\n",
    "- **Split:** Spatial 80/20 (same as gnn-maps-3)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c491a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch Geometric and its dependencies (Kaggle-compatible)\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "\n",
    "!pip install -q torch-geometric\n",
    "\n",
    "import torch\n",
    "pytorch_version = torch.__version__.split('+')[0]\n",
    "cuda_version = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"\\nInstalling PyG extensions for PyTorch {pytorch_version} and CUDA {cuda_version}...\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    !pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{pytorch_version}+cu{cuda_version}.html\n",
    "else:\n",
    "    !pip install -q torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{pytorch_version}+cpu.html\n",
    "\n",
    "print(\"\\n‚úÖ PyTorch Geometric installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4703876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick verification test\n",
    "try:\n",
    "    import torch\n",
    "    from torch_geometric.nn import SAGEConv\n",
    "    \n",
    "    test_conv = SAGEConv(16, 32)\n",
    "    print(\"‚úÖ PyTorch Geometric is working correctly!\")\n",
    "    print(f\"   Test layer created: {test_conv}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    print(\"Please re-run the installation cell above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c9515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"‚úÖ All libraries loaded successfully!\")\n",
    "print(f\"   - PyTorch version: {torch.__version__}\")\n",
    "print(f\"   - CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"   - Device: {'GPU' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4606982",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/chl-codex-annotated/cHL_CODEX_annotation.csv\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "display(df.head())\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec45392",
   "metadata": {},
   "source": [
    "# 2. Data Preparation & Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25d29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"OPTION 3: HYBRID MODEL (PROTEIN + SPATIAL FEATURES)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Column definitions\n",
    "x_col = 'X_cent'\n",
    "y_col = 'Y_cent'  \n",
    "label_col = 'cellType'\n",
    "\n",
    "marker_cols = [\n",
    "    'BCL.2', 'CCR6', 'CD11b', 'CD11c', 'CD15', 'CD16', 'CD162', 'CD163', \n",
    "    'CD2', 'CD20', 'CD206', 'CD25', 'CD30', 'CD31', 'CD4', 'CD44', \n",
    "    'CD45RA', 'CD45RO', 'CD45', 'CD5', 'CD56', 'CD57', 'CD68', 'CD69', \n",
    "    'CD7', 'CD8', 'Collagen.4', 'Cytokeratin', 'DAPI.01', 'EGFR', \n",
    "    'FoxP3', 'Granzyme.B', 'HLA.DR', 'IDO.1', 'LAG.3', 'MCT', 'MMP.9', \n",
    "    'MUC.1', 'PD.1', 'PD.L1', 'Podoplanin', 'T.bet', 'TCR.g.d', 'TCRb', \n",
    "    'Tim.3', 'VISA', 'Vimentin', 'a.SMA', 'b.Catenin'\n",
    "]\n",
    "\n",
    "print(f\"\\n‚úÖ Using {len(marker_cols)} protein markers\")\n",
    "print(f\"‚úÖ Total cells: {len(df):,}\")\n",
    "print(f\"‚úÖ Cell types: {df[label_col].nunique()}\")\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(df[marker_cols].values)\n",
    "x = torch.tensor(X_normalized, dtype=torch.float)\n",
    "\n",
    "# Encode labels\n",
    "unique_labels = sorted(df[label_col].unique())\n",
    "label_map = {name: i for i, name in enumerate(unique_labels)}\n",
    "y = torch.tensor(df[label_col].map(label_map).values, dtype=torch.long)\n",
    "num_classes = len(label_map)\n",
    "\n",
    "print(f\"\\nüìä {num_classes} cell types encoded\")\n",
    "\n",
    "# Build KNN graph\n",
    "print(f\"\\nüîó Building KNN Graph (K=5)...\")\n",
    "k_neighbors = 5\n",
    "coords = df[[x_col, y_col]].values\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors=k_neighbors + 1, algorithm='ball_tree').fit(coords)\n",
    "distances, indices = nbrs.kneighbors(coords)\n",
    "\n",
    "source_nodes = np.repeat(np.arange(len(df)), k_neighbors)\n",
    "target_nodes = indices[:, 1:].flatten()\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long)\n",
    "\n",
    "print(f\"‚úÖ Graph: {edge_index.shape[1]:,} edges\")\n",
    "\n",
    "# Spatial split (80/20 by X-axis)\n",
    "print(f\"\\n\" + \"=\" * 80)\n",
    "print(\"SPATIAL TRAIN/TEST SPLIT (80/20 by X-axis)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "x_min = df[x_col].min()\n",
    "x_max = df[x_col].max()\n",
    "x_threshold = x_min + (0.8 * (x_max - x_min))\n",
    "\n",
    "train_mask = torch.tensor(df[x_col].values <= x_threshold, dtype=torch.bool)\n",
    "test_mask = torch.tensor(df[x_col].values > x_threshold, dtype=torch.bool)\n",
    "\n",
    "print(f\"\\n‚úÖ SPATIAL SPLIT\")\n",
    "print(f\"   Train: {train_mask.sum():,} cells ({100*train_mask.float().mean():.1f}%)\")\n",
    "print(f\"   Test:  {test_mask.sum():,} cells ({100*test_mask.float().mean():.1f}%)\")\n",
    "print(f\"   This is the SAME split as gnn-maps-3 (for fair comparison)\")\n",
    "\n",
    "# Create PyG Data object\n",
    "data = Data(\n",
    "    x=x,\n",
    "    edge_index=edge_index,\n",
    "    y=y,\n",
    "    train_mask=train_mask,\n",
    "    test_mask=test_mask\n",
    ")\n",
    "\n",
    "print(f\"\\n{data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80b2474",
   "metadata": {},
   "source": [
    "# 3. Hybrid Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf40cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"HYBRID MODEL: MLP + GNN FUSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class HybridGNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Hybrid Model: Combines MLP (protein features) + GNN (spatial context)\n",
    "    \n",
    "    Architecture:\n",
    "    1. MLP Branch: 4-layer network (MAPS-style) processes protein markers\n",
    "    2. GNN Branch: 2-layer GraphSAGE aggregates spatial neighborhood info\n",
    "    3. Fusion: Concatenate [MLP features + GNN features] ‚Üí classifier\n",
    "    \n",
    "    This gives the best of both worlds:\n",
    "    - Strong protein marker features (like MAPS)\n",
    "    - Rich spatial context (like pure GNN)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # MLP Branch (processes protein markers independently)\n",
    "        self.mlp_fc1 = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.mlp_fc2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.mlp_fc3 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.mlp_fc4 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # GNN Branch (aggregates spatial neighborhood)\n",
    "        self.gnn_conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.gnn_conv2 = SAGEConv(hidden_channels, hidden_channels)\n",
    "        \n",
    "        # Fusion layer (combines both representations)\n",
    "        self.classifier = torch.nn.Linear(hidden_channels * 2, out_channels)\n",
    "        \n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # MLP Branch: Process protein markers\n",
    "        mlp_out = F.relu(self.mlp_fc1(x))\n",
    "        mlp_out = F.dropout(mlp_out, p=self.dropout, training=self.training)\n",
    "        mlp_out = F.relu(self.mlp_fc2(mlp_out))\n",
    "        mlp_out = F.dropout(mlp_out, p=self.dropout, training=self.training)\n",
    "        mlp_out = F.relu(self.mlp_fc3(mlp_out))\n",
    "        mlp_out = F.dropout(mlp_out, p=self.dropout, training=self.training)\n",
    "        mlp_out = F.relu(self.mlp_fc4(mlp_out))\n",
    "        mlp_out = F.dropout(mlp_out, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # GNN Branch: Aggregate spatial context\n",
    "        gnn_out = self.gnn_conv1(x, edge_index)\n",
    "        gnn_out = F.relu(gnn_out)\n",
    "        gnn_out = F.dropout(gnn_out, p=self.dropout, training=self.training)\n",
    "        gnn_out = self.gnn_conv2(gnn_out, edge_index)\n",
    "        gnn_out = F.relu(gnn_out)\n",
    "        gnn_out = F.dropout(gnn_out, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Fusion: Concatenate both representations\n",
    "        combined = torch.cat([mlp_out, gnn_out], dim=1)\n",
    "        \n",
    "        # Final classification\n",
    "        out = self.classifier(combined)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "# Also keep baseline models for comparison\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(in_channels, hidden_channels)\n",
    "        self.fc2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc3 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.fc4 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
    "        self.classifier = torch.nn.Linear(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index=None):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "print(\"\\n‚úÖ Models defined:\")\n",
    "print(\"   1. MLP (baseline - protein only)\")\n",
    "print(\"   2. GraphSAGE (baseline - spatial only)\")\n",
    "print(\"   3. HybridGNN (protein + spatial)\")\n",
    "print(\"\\nüî¨ Hybrid Architecture:\")\n",
    "print(\"   Input (49 markers) ‚Üí\")\n",
    "print(\"   ‚îú‚îÄ MLP: 49 ‚Üí 512 ‚Üí 512 ‚Üí 512 ‚Üí 512\")\n",
    "print(\"   ‚îî‚îÄ GNN: 49 ‚Üí 512 ‚Üí 512\")\n",
    "print(\"   Concat: [512 MLP + 512 GNN] = 1024\")\n",
    "print(\"   Classifier: 1024 ‚Üí num_classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7715cc0",
   "metadata": {},
   "source": [
    "# 4. Training (All Three Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc2dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üíª Device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Hyperparameters\n",
    "hidden_dim = 512\n",
    "dropout = 0.1\n",
    "lr = 0.001\n",
    "max_epochs = 500\n",
    "min_epochs = 250\n",
    "patience = 100\n",
    "\n",
    "print(f\"\\n‚öôÔ∏è  Hyperparameters: hidden={hidden_dim}, epochs={max_epochs}\")\n",
    "\n",
    "# Training functions\n",
    "def train_epoch_with_loss(model, data, optimizer):\n",
    "    model.train()\n",
    "    data = data.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, data, mask):\n",
    "    model.eval()\n",
    "    data_device = data.to(device)\n",
    "    out = model(data_device.x, data_device.edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    \n",
    "    y_true = data_device.y[mask].cpu().numpy()\n",
    "    y_pred = pred[mask].cpu().numpy()\n",
    "    \n",
    "    acc = (pred[mask] == data_device.y[mask]).sum().item() / mask.sum().item()\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    return acc, f1\n",
    "\n",
    "# Function to train any model\n",
    "def train_model(model, model_name, data, lr, max_epochs, min_epochs, patience):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"TRAINING {model_name}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    print(f\"\\nEpoch | Loss    | Train Acc | Train F1 | Test Acc | Test F1 | Status\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    best_f1 = 0\n",
    "    best_epoch = 0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        loss = train_epoch_with_loss(model, data, optimizer)\n",
    "        \n",
    "        if epoch % 10 == 0 or epoch == 1:\n",
    "            train_acc, train_f1 = evaluate(model, data, data.train_mask)\n",
    "            test_acc, test_f1 = evaluate(model, data, data.test_mask)\n",
    "            \n",
    "            status = \"\"\n",
    "            if test_f1 > best_f1:\n",
    "                best_f1 = test_f1\n",
    "                best_epoch = epoch\n",
    "                patience_counter = 0\n",
    "                status = \"‚úÖ BEST\"\n",
    "            else:\n",
    "                patience_counter += 10\n",
    "                if epoch >= min_epochs and patience_counter >= patience:\n",
    "                    status = \"üõë EARLY STOP\"\n",
    "                \n",
    "            print(f'{epoch:5d} | {loss:7.4f} | {train_acc:9.4f} | {train_f1:8.4f} | '\n",
    "                  f'{test_acc:8.4f} | {test_f1:7.4f} | {status}')\n",
    "            \n",
    "            if epoch >= min_epochs and patience_counter >= patience:\n",
    "                print(f\"\\n‚è∏Ô∏è  Early stopping!\")\n",
    "                break\n",
    "    \n",
    "    print(f\"\\n‚úÖ {model_name} Complete! Best F1: {best_f1:.4f} (epoch {best_epoch})\")\n",
    "    return best_f1, best_epoch\n",
    "\n",
    "# Train all three models\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING ALL MODELS FOR COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. MLP Baseline\n",
    "mlp_model = MLP(len(marker_cols), hidden_dim, num_classes, dropout).to(device)\n",
    "mlp_f1, mlp_epoch = train_model(mlp_model, \"MLP (Baseline)\", data, lr, max_epochs, min_epochs, patience)\n",
    "\n",
    "# 2. GraphSAGE Baseline\n",
    "gnn_model = GraphSAGE(len(marker_cols), hidden_dim, num_classes, dropout).to(device)\n",
    "gnn_f1, gnn_epoch = train_model(gnn_model, \"GraphSAGE (Baseline)\", data, lr, max_epochs, min_epochs, patience)\n",
    "\n",
    "# 3. Hybrid Model (STAR OF THE SHOW!)\n",
    "hybrid_model = HybridGNN(len(marker_cols), hidden_dim, num_classes, dropout).to(device)\n",
    "hybrid_f1, hybrid_epoch = train_model(hybrid_model, \"HybridGNN (Protein+Spatial)\", data, lr, max_epochs, min_epochs, patience)\n",
    "\n",
    "# ==========================================\n",
    "# FINAL COMPARISON\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULTS: THREE-WAY COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get final test scores\n",
    "mlp_test_acc, mlp_test_f1 = evaluate(mlp_model, data, data.test_mask)\n",
    "gnn_test_acc, gnn_test_f1 = evaluate(gnn_model, data, data.test_mask)\n",
    "hybrid_test_acc, hybrid_test_f1 = evaluate(hybrid_model, data, data.test_mask)\n",
    "\n",
    "print(f\"\\n{'Model':<30s} {'Accuracy':>12s} {'F1-Score':>12s} {'vs MAPS':>12s}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'MAPS (Paper Baseline)':<30s} {'N/A':>12s} {'0.9000':>12s} {'1.00x':>12s}\")\n",
    "print(f\"{'MLP (Protein Only)':<30s} {mlp_test_acc:>12.4f} {mlp_test_f1:>12.4f} {mlp_test_f1/0.90:>11.2f}x\")\n",
    "print(f\"{'GraphSAGE (Spatial Only)':<30s} {gnn_test_acc:>12.4f} {gnn_test_f1:>12.4f} {gnn_test_f1/0.90:>11.2f}x\")\n",
    "print(f\"{'HybridGNN (Protein+Spatial)':<30s} {hybrid_test_acc:>12.4f} {hybrid_test_f1:>12.4f} {hybrid_test_f1/0.90:>11.2f}x\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "# Analysis\n",
    "print(f\"\\nüìä Performance Analysis:\")\n",
    "print(f\"   Hybrid vs MLP:  {(hybrid_test_f1 - mlp_test_f1)*100:+.2f} pp ({((hybrid_test_f1 - mlp_test_f1)/mlp_test_f1)*100:+.1f}%)\")\n",
    "print(f\"   Hybrid vs GNN:  {(hybrid_test_f1 - gnn_test_f1)*100:+.2f} pp ({((hybrid_test_f1 - gnn_test_f1)/gnn_test_f1)*100:+.1f}%)\")\n",
    "print(f\"   Hybrid vs MAPS: {(hybrid_test_f1 - 0.90)*100:+.2f} pp ({((hybrid_test_f1 - 0.90)/0.90)*100:+.1f}%)\")\n",
    "\n",
    "# Determine winner\n",
    "best_model = max([(mlp_test_f1, 'MLP'), (gnn_test_f1, 'GraphSAGE'), (hybrid_test_f1, 'Hybrid')], key=lambda x: x[0])\n",
    "print(f\"\\nüèÜ Best Model: {best_model[1]} with {best_model[0]:.1%} F1\")\n",
    "\n",
    "if hybrid_test_f1 > max(mlp_test_f1, gnn_test_f1):\n",
    "    print(f\"\\n‚úÖ HYBRID MODEL WINS!\")\n",
    "    print(f\"   Combining protein + spatial features beats both baselines!\")\n",
    "    if hybrid_test_f1 > 0.90:\n",
    "        print(f\"   üéâ AND IT BEATS MAPS (90%)!\")\n",
    "elif mlp_test_f1 > gnn_test_f1:\n",
    "    print(f\"\\nüìä MLP wins (protein features stronger than spatial for this split)\")\n",
    "else:\n",
    "    print(f\"\\nüìä GNN wins (spatial context helps despite distribution shift)\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart comparison\n",
    "ax = axes[0]\n",
    "models = ['MAPS\\n(Paper)', 'MLP\\n(Protein)', 'GNN\\n(Spatial)', 'Hybrid\\n(Both)']\n",
    "f1_scores = [0.90, mlp_test_f1, gnn_test_f1, hybrid_test_f1]\n",
    "colors = ['#2ecc71', '#3498db', '#e74c3c', '#9b59b6']\n",
    "\n",
    "bars = ax.bar(models, f1_scores, color=colors, edgecolor='black', linewidth=2, width=0.6)\n",
    "ax.set_ylabel('F1-Score', fontsize=14, fontweight='bold')\n",
    "ax.set_title('Hybrid Model: Protein + Spatial Features', fontsize=16, fontweight='bold')\n",
    "ax.set_ylim([0, 1.0])\n",
    "ax.axhline(y=0.90, color='green', linestyle='--', linewidth=2, alpha=0.5, label='MAPS Target')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.legend(fontsize=11)\n",
    "\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:.4f}',\n",
    "            ha='center', va='bottom', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Improvement breakdown\n",
    "ax2 = axes[1]\n",
    "comparisons = ['MLP vs\\nMAPS', 'GNN vs\\nMAPS', 'Hybrid vs\\nMAPS', 'Hybrid vs\\nMLP', 'Hybrid vs\\nGNN']\n",
    "improvements = [\n",
    "    (mlp_test_f1 - 0.90) * 100,\n",
    "    (gnn_test_f1 - 0.90) * 100,\n",
    "    (hybrid_test_f1 - 0.90) * 100,\n",
    "    (hybrid_test_f1 - mlp_test_f1) * 100,\n",
    "    (hybrid_test_f1 - gnn_test_f1) * 100\n",
    "]\n",
    "colors2 = ['#3498db' if v >= 0 else '#e67e22' for v in improvements]\n",
    "\n",
    "bars2 = ax2.bar(comparisons, improvements, color=colors2, edgecolor='black', linewidth=1.5)\n",
    "ax2.set_ylabel('Improvement (%)', fontsize=14, fontweight='bold')\n",
    "ax2.set_title('Performance Improvements', fontsize=16, fontweight='bold')\n",
    "ax2.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{height:+.1f}%',\n",
    "            ha='center', va='bottom' if height > 0 else 'top', fontsize=11, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üöÄ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüíª Hardware: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"‚öôÔ∏è  Config: Spatial Split, Hybrid Architecture, hidden=512\")\n",
    "print(f\"üìä Final Results:\")\n",
    "print(f\"   MLP:      {mlp_test_f1:.1%}\")\n",
    "print(f\"   GNN:      {gnn_test_f1:.1%}\")\n",
    "print(f\"   Hybrid:   {hybrid_test_f1:.1%}\")\n",
    "print(f\"   MAPS:     90.0%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
